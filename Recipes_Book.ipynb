{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOEvrI0xg0psKQZY4h9kj6N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7228c9c274ab4b628ca84bfb1a064fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d0e442f4c474f73bce0eb44a646776f",
              "IPY_MODEL_ede8bbc0f0734b5abb51e8dd5cc159bf",
              "IPY_MODEL_7060df2516f641da8db2490417acfadd"
            ],
            "layout": "IPY_MODEL_c7d30b6e864645bd81177a04708f0e9c"
          }
        },
        "7d0e442f4c474f73bce0eb44a646776f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_963aa7b53bb048c9a1a8483c448c2c31",
            "placeholder": "​",
            "style": "IPY_MODEL_edf823ed3c95479b837682f8b97d1254",
            "value": "(…)pt2-finetuned-recipes-cooking.IQ3_M.gguf: 100%"
          }
        },
        "ede8bbc0f0734b5abb51e8dd5cc159bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29f5e3661e56425295eaca0fc278d522",
            "max": 94221920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2254103ba0284bb9af0861428b026281",
            "value": 94221920
          }
        },
        "7060df2516f641da8db2490417acfadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dd6e3f5a93f4d4f882c6b330e162e2d",
            "placeholder": "​",
            "style": "IPY_MODEL_0db755ac505c4f59ad79195f22093d52",
            "value": " 94.2M/94.2M [00:04&lt;00:00, 20.6MB/s]"
          }
        },
        "c7d30b6e864645bd81177a04708f0e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "963aa7b53bb048c9a1a8483c448c2c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf823ed3c95479b837682f8b97d1254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29f5e3661e56425295eaca0fc278d522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2254103ba0284bb9af0861428b026281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dd6e3f5a93f4d4f882c6b330e162e2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0db755ac505c4f59ad79195f22093d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudaidhanif/Recipe_Generator.py/blob/main/Recipes_Book.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python\n",
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fSpvCZ8UWAj",
        "outputId": "d9da2c3a-3de6-48bb-c448-687ab3d30ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Using cached llama_cpp_python-0.3.1.tar.gz (63.9 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.26.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.1)\n",
            "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.1-cp310-cp310-linux_x86_64.whl size=3485366 sha256=d30c88d42b70713c019e35132feedc99d861fb38bbbf88b10c58af07b267d87a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/b0/a2/f47d952aec7ab061b9e2a345e23a1e1e137beb7891259e3d0c\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "# Load the pre-trained model from Hugging Face\n",
        "llm = Llama.from_pretrained(\n",
        "    repo_id=\"RichardErkhov/mrm8488_-_gpt2-finetuned-recipes-cooking-gguf\",\n",
        "    filename=\"gpt2-finetuned-recipes-cooking.IQ3_M.gguf\",\n",
        ")\n",
        "\n",
        "# Function to generate a recipe based on user input\n",
        "def generate_recipe(dish_name):\n",
        "    response = llm.create_chat_completion(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Give me a recipe for {dish_name}\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# Example usage in Google Colab\n",
        "dish = \"chocolate cake\"\n",
        "recipe = generate_recipe(dish)\n",
        "print(f\"Recipe for {dish}: {recipe}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7228c9c274ab4b628ca84bfb1a064fe5",
            "7d0e442f4c474f73bce0eb44a646776f",
            "ede8bbc0f0734b5abb51e8dd5cc159bf",
            "7060df2516f641da8db2490417acfadd",
            "c7d30b6e864645bd81177a04708f0e9c",
            "963aa7b53bb048c9a1a8483c448c2c31",
            "edf823ed3c95479b837682f8b97d1254",
            "29f5e3661e56425295eaca0fc278d522",
            "2254103ba0284bb9af0861428b026281",
            "6dd6e3f5a93f4d4f882c6b330e162e2d",
            "0db755ac505c4f59ad79195f22093d52"
          ]
        },
        "id": "X7rf993UUfA7",
        "outputId": "14481140-ad05-45af-f202-531332ae2f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)pt2-finetuned-recipes-cooking.IQ3_M.gguf:   0%|          | 0.00/94.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7228c9c274ab4b628ca84bfb1a064fe5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 149 tensors from /root/.cache/huggingface/hub/models--RichardErkhov--mrm8488_-_gpt2-finetuned-recipes-cooking-gguf/snapshots/1d6bc2a11abf6319ffe718d24fbc93bf3863abd7/./gpt2-finetuned-recipes-cooking.IQ3_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gpt2\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gpt2 Finetuned Recipes Cooking\n",
            "llama_model_loader: - kv   3:                         general.size_label str              = 163M\n",
            "llama_model_loader: - kv   4:                          general.languages arr[str,1]       = [\"en\"]\n",
            "llama_model_loader: - kv   5:                           gpt2.block_count u32              = 12\n",
            "llama_model_loader: - kv   6:                        gpt2.context_length u32              = 1024\n",
            "llama_model_loader: - kv   7:                      gpt2.embedding_length u32              = 768\n",
            "llama_model_loader: - kv   8:                   gpt2.feed_forward_length u32              = 3072\n",
            "llama_model_loader: - kv   9:                  gpt2.attention.head_count u32              = 12\n",
            "llama_model_loader: - kv  10:          gpt2.attention.layer_norm_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 27\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  13:                         tokenizer.ggml.pre str              = gpt-2\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,50257]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,50257]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ġ t\", \"Ġ a\", \"h e\", \"i n\", \"r e\",...\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 50256\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 50256\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   99 tensors\n",
            "llama_model_loader: - type q4_K:   25 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llama_model_loader: - type iq3_s:   24 tensors\n",
            "llm_load_vocab: special tokens cache size = 1\n",
            "llm_load_vocab: token to piece cache size = 0.3060 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = gpt2\n",
            "llm_load_print_meta: vocab type       = BPE\n",
            "llm_load_print_meta: n_vocab          = 50257\n",
            "llm_load_print_meta: n_merges         = 50000\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 1024\n",
            "llm_load_print_meta: n_embd           = 768\n",
            "llm_load_print_meta: n_layer          = 12\n",
            "llm_load_print_meta: n_head           = 12\n",
            "llm_load_print_meta: n_head_kv        = 12\n",
            "llm_load_print_meta: n_rot            = 64\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 64\n",
            "llm_load_print_meta: n_embd_head_v    = 64\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 768\n",
            "llm_load_print_meta: n_embd_v_gqa     = 768\n",
            "llm_load_print_meta: f_norm_eps       = 1.0e-05\n",
            "llm_load_print_meta: f_norm_rms_eps   = 0.0e+00\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 3072\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = -1\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 1024\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 0.1B\n",
            "llm_load_print_meta: model ftype      = IQ3_S mix - 3.66 bpw\n",
            "llm_load_print_meta: model params     = 163.04 M\n",
            "llm_load_print_meta: model size       = 88.16 MiB (4.54 BPW) \n",
            "llm_load_print_meta: general.name     = Gpt2 Finetuned Recipes Cooking\n",
            "llm_load_print_meta: BOS token        = 50256 '<|endoftext|>'\n",
            "llm_load_print_meta: EOS token        = 50256 '<|endoftext|>'\n",
            "llm_load_print_meta: LF token         = 128 'Ä'\n",
            "llm_load_print_meta: EOT token        = 50256 '<|endoftext|>'\n",
            "llm_load_print_meta: EOG token        = 50256 '<|endoftext|>'\n",
            "llm_load_print_meta: max token length = 256\n",
            "llm_load_tensors: ggml ctx size =    0.07 MiB\n",
            "llm_load_tensors:        CPU buffer size =    88.16 MiB\n",
            ".............................................\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =    18.00 MiB\n",
            "llama_new_context_with_model: KV self size  =   18.00 MiB, K (f16):    9.00 MiB, V (f16):    9.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.19 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   101.16 MiB\n",
            "llama_new_context_with_model: graph nodes  = 453\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.eos_token_id': '50256', 'tokenizer.ggml.bos_token_id': '50256', 'general.architecture': 'gpt2', 'gpt2.context_length': '1024', 'gpt2.attention.layer_norm_epsilon': '0.000010', 'general.type': 'model', 'general.size_label': '163M', 'gpt2.block_count': '12', 'gpt2.embedding_length': '768', 'gpt2.attention.head_count': '12', 'general.file_type': '27', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.name': 'Gpt2 Finetuned Recipes Cooking', 'gpt2.feed_forward_length': '3072', 'tokenizer.ggml.pre': 'gpt-2'}\n",
            "Using fallback chat format: llama-2\n",
            "llama_perf_context_print:        load time =     254.95 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /   495 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13849.83 ms /   511 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recipe for chocolate cake: \n",
            "I think it's better if you use chocolate chips or other types of nuts\n",
            "However\n",
            "If you don't\n",
            "You can use any type of nuts you like\n",
            "It will still be a great flavor to eat when you eat it\n",
            "However\n",
            "I also would advise to add 1 tablespoon of sugar to this recipe to your taste\n",
            "You can also add some chopped toasted pecans and / or raisins if you have them\n",
            "I really love the aroma of the vanilla sugar and it adds a nice fragrance to the whole process\n",
            "I don't know any of your recipes or know how it makes you feel about chocolate cake ?\n",
            "\n",
            "Butterscotch cake with butter frosting:\n",
            "\n",
            "Preheat oven to 350f grease and flour two 9 inch round cake pans\n",
            "Prepare and bake cake mix according to package directions and allow to stand at room temperature\n",
            "About 45 minutes\n",
            "In a saucepan\n",
            "Combine brown sugar\n",
            "Margarine\n",
            "And water until sugar is completely dissolved\n",
            "Stir in butterscotch chips\n",
            "Mixing thoroughly\n",
            "Pour evenly into prepared pans\n",
            "Bake at 350 degrees for 40 minutes or until a cake tester comes out clean\n",
            "In a saucepan\n",
            "Combine the butterscotch chips\n",
            "And brown sugar\n",
            "Boil over low heat for 3-4 minutes\n",
            "Stirring constantly\n",
            "Remove pan from heat and allow to cool to room temperature\n",
            "In a food processor\n",
            "Blend together the cream cheese\n",
            "Eggs and vanilla\n",
            "Mixing thoroughly\n",
            "Stir the cooled coffee and the powdered sugar into the whipped cream\n",
            "Pour over the cake\n",
            "\n",
            "Butterscotch chip cookies:\n",
            "\n",
            "In a large bowl\n",
            "Cream butter and sugar\n",
            "Add egg and vanilla\n",
            "Beat well\n",
            "Combine flour and baking soda\n",
            "Stir into creamed mixture\n",
            "Chill dough 1 hour or until easy to handle\n",
            "Roll into 1-inch balls\n",
            "Roll each ball in butterscotch chips\n",
            "Roll in chips\n",
            "Bake at 350 for 10-12 minutes or until edges are lightly browned\n",
            "\n",
            "Butterscotch chocolate cake:\n",
            "\n",
            "Preheat oven to 325 degrees\n",
            "Grease and flour two 9 inch round cake pans\n",
            "Prepare and bake cake mix according to package directions and allow to stand at room temperature for 45 minutes\n",
            "In a saucepan\n",
            "Combine brown sugar and butter\n",
            "Bring to a boil over medium high heat\n",
            "Stirring constantly\n",
            "Boil\n"
          ]
        }
      ]
    }
  ]
}